{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### 版權 2024 Google LLC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUOiKRSF7jc1"
      },
      "source": [
        "# 使用 JAX 和 Flax 在 Gemma 上進行推論\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60KmTK7o6ppd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemma/docs/jax_inference\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />在 ai.google.dev 上檢視</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/doggy8088/generative-ai-docs/blob/main/site/zh/gemma/docs/jax_inference.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />在 Google Colab 中執行</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/google/generative-ai-docs/main/site/en/gemma/docs/jax_inference.ipynb\"><img src=\"https://ai.google.dev/images/cloud-icon.svg\" width=\"40\" />在 Vertex AI 中開啟</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/doggy8088/generative-ai-docs/blob/main/site/zh/gemma/docs/jax_inference.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />在 GitHub 上檢視原始程式碼</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tdlq6K0znh3O"
      },
      "source": [
        "## 概觀\n",
        "\n",
        "Gemma 是基於 Google DeepMind Gemini 研究技術的輕量級、最先進的開放大型語言模型系列。本教學示範如何使用 [Google DeepMind 的 `gemma` 函式庫](https://github.com/google-deepmind/gemma) 對 Gemma 2B Instruct 模型進行基本取樣/推理。函式庫是以 [JAX](https://jax.readthedocs.io)(高性能數值運算函式庫)、[Flax](https://flax.readthedocs.io)(基於 JAX 的神經網路函式庫)、[Orbax](https://orbax.readthedocs.io/)(用於訓練工具的基於 JAX 的函式庫，例如檢查點) 和 [SentencePiece](https://github.com/google/sentencepiece)(分詞器/去分詞器函式庫) 編寫。儘管此筆記本沒有直接使用 Flax，但 Flax 已用於建立 Gemma。\n",
        "\n",
        "此筆記本可在 Google Colab 上執行，配備免費 T4 GPU (前往**編輯** > **筆記設定** > 在**硬體加速器** 底下選擇**T4 GPU** )。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKvTsIkL98BG"
      },
      "source": [
        "## 設定\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCgCkmQSPxkE"
      },
      "source": [
        "### 1. 為 Gemma 設定 Kaggle 存取權\n",
        "\n",
        "要完成本教學課程，需要先按照 [Gemma 設定](https://ai.google.dev/gemma/docs/setup) 中的設定說明進行操作，了解如何執行下列動作：\n",
        "\n",
        "* 在 [kaggle.com](https://www.kaggle.com/models/google/gemma/) 上取得 Gemma 存取權。\n",
        "* 選取具有足夠資源來執行 Gemma 模型的 Colab 執行時期。\n",
        "* 產生並設定 Kaggle 使用者名稱和 API 金鑰。\n",
        "\n",
        "完成 Gemma 設定後，請移至下一章節，設定 Colab 環境的環境變數。\n",
        "\n",
        "### 2. 設定環境變數\n",
        "\n",
        "設定 `KAGGLE_USERNAME` 和 `KAGGLE_KEY` 的環境變數。當出現「授予存取權？」訊息時，請同意提供機密存取權。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lKoW-nhE-gNO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata # `userdata` is a Colab API.\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO7a1Q4Yyc9Z"
      },
      "source": [
        "### 3. 安裝 `gemma` 函式庫\n",
        "\n",
        "本筆記本專注於使用免費的 Colab GPU。若要啟用硬體加速，請按一下 **編輯** > **筆記本設定** > 選取 **T4 GPU** > **儲存** 。\n",
        "\n",
        "接著，你需要從 [`github.com/google-deepmind/gemma`](https://github.com/google-deepmind/gemma) 安裝 Google DeepMind 的 `gemma` 函式庫。如果你收到關於「pip 的相依關系解析器」錯誤，通常可以忽略它。\n",
        "\n",
        "**注意：** 安裝 `gemma` 後，你也會安裝 [`flax`](https://flax.readthedocs.io)、[`jax`](https://jax.readthedocs.io) 核心、[`optax`](https://optax.readthedocs.io/en/latest/)(JAX-based 的梯度處理和最佳化函式庫)、[`orbax`](https://orbax.readthedocs.io/)、[`sentencepiece`](https://github.com/google/sentencepiece)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WWEzVJR4Fx9g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.4/244.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gemma (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/google-deepmind/gemma.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKLjBAe1m3Ck"
      },
      "source": [
        "## 載入並準備 Gemma 模型\n",
        "\n",
        "1. 使用 [`kagglehub.model_download`](https://github.com/Kaggle/kagglehub/blob/bddefc718182282882b72f814d407d89e5d178c4/src/kagglehub/models.py#L12) 載入 Gemma 模型，此函式需要三個參數：\n",
        "\n",
        "- `handle`：Kaggle 的模型代號\n",
        "- `path`：(Optional string) 本機路徑\n",
        "- `force_download`：(Optional boolean) 強制重新載入模型\n",
        "\n",
        "**注意：** Gemma 模型大約有 3.7Gb 大。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_W3FUd9lt8VT"
      },
      "outputs": [],
      "source": [
        "GEMMA_VARIANT = '2b-it' # @param ['2b', '2b-it'] {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kFCmWEKdMA_Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/google/gemma/flax/2b-it/2/download...\n",
            "100%|██████████| 3.67G/3.67G [00:35<00:00, 110MB/s]\n",
            "Extracting model files...\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "GEMMA_PATH = kagglehub.model_download(f'google/gemma/flax/{GEMMA_VARIANT}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nYmYTMk8aELi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GEMMA_PATH: /root/.cache/kagglehub/models/google/gemma/flax/2b-it/2\n"
          ]
        }
      ],
      "source": [
        "print('GEMMA_PATH:', GEMMA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytNi47xSlw71"
      },
      "source": [
        "**提示：** 上方的輸出路徑是模型權重和 tokenizer 本機儲存的位置，你稍後會用到它們。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92BcvYdemXbd"
      },
      "source": [
        "2. 檢查模型權重和 tokenizer 的位置，然後設定路徑變數。tokenizer 目錄將位於你下載模型的主目錄中，而模型權重則位於子目錄中。例如：\n",
        "\n",
        "- `tokenizer.model` 檔案將位於 `/LOCAL/PATH/TO/gemma/flax/2b-it/2`)。\n",
        "- 模型檢查點將位於 `/LOCAL/PATH/TO/gemma/flax/2b-it/2/2b-it`)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QY6OnASOpZbW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CKPT_PATH: /root/.cache/kagglehub/models/google/gemma/flax/2b-it/2/2b-it\n",
            "TOKENIZER_PATH: /root/.cache/kagglehub/models/google/gemma/flax/2b-it/2/tokenizer.model\n"
          ]
        }
      ],
      "source": [
        "CKPT_PATH = os.path.join(GEMMA_PATH, GEMMA_VARIANT)\n",
        "TOKENIZER_PATH = os.path.join(GEMMA_PATH, 'tokenizer.model')\n",
        "print('CKPT_PATH:', CKPT_PATH)\n",
        "print('TOKENIZER_PATH:', TOKENIZER_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc0ZzYIW0TSN"
      },
      "source": [
        "## 進行取樣/推論\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEe3p8geqekV"
      },
      "source": [
        "1. 使用[`gemma.params.load_and_format_params`](https://github.com/google-deepmind/gemma/blob/c6bd156c246530e1620a7c62de98542a377e3934/gemma/params.py#L27) 方法載入並格式化 Gemma 模型檢查點:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mnr52JQVqKRw"
      },
      "outputs": [],
      "source": [
        "from gemma import params as params_lib\n",
        "\n",
        "params = params_lib.load_and_format_params(CKPT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xpnb2igrGjk"
      },
      "source": [
        "2. 載入 Gemma tokenizer，結構化使用 [`sentencepiece.SentencePieceProcessor`](https://github.com/google/sentencepiece/blob/4d6a1f41069c4636c51a5590f7578a0dbed83450/python/src/sentencepiece/__init__.py#L423)：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-T0ZHff5rNSy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.Load(TOKENIZER_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkAf4fkNrY-3"
      },
      "source": [
        "3. 若要從 Gemma 模型檢查點自動載入正確設定，請使用 [`gemma.transformer.TransformerConfig`](https://github.com/google-deepmind/gemma/blob/56e501ce147af4ea5c23cc0ddf5a9c4a6b7bd0d0/gemma/transformer.py#L65)。 `cache_size` 參數是在 Gemma `Transformer` 快取中的時間步驟數目。之後，使用 [`gemma.transformer.Transformer`](https://github.com/google-deepmind/gemma/blob/56e501ce147af4ea5c23cc0ddf5a9c4a6b7bd0d0/gemma/transformer.py#L136) 將 Gemma 模型例項化為 `transformer` (繼承自 [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html))。\n",
        "\n",
        "**注意：** 因為在目前的 Gemma 發行版本中沒有使用 Token，所以詞彙量小於輸入嵌入的數量。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4PNWxDhvrRXJ"
      },
      "outputs": [],
      "source": [
        "from gemma import transformer as transformer_lib\n",
        "\n",
        "transformer_config = transformer_lib.TransformerConfig.from_params(\n",
        "    params=params,\n",
        "    cache_size=1024\n",
        ")\n",
        "\n",
        "transformer = transformer_lib.Transformer(transformer_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs0vgmXVroBq"
      },
      "source": [
        "3. 在 Gemma 模型檢查點/權重和分詞器之上使用 [`gemma.sampler.Sampler`](https://github.com/google-deepmind/gemma/blob/c6bd156c246530e1620a7c62de98542a377e3934/gemma/sampler.py#L88) 建立一個 `sampler`：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4GX4pFP6rtyN"
      },
      "outputs": [],
      "source": [
        "from gemma import sampler as sampler_lib\n",
        "\n",
        "sampler = sampler_lib.Sampler(\n",
        "    transformer=transformer,\n",
        "    vocab=vocab,\n",
        "    params=params['transformer'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9yU99Xxr59w"
      },
      "source": [
        "4. 在 `input_batch` 中撰寫提示並執行推斷。你可以調整 `total_generation_steps` (生成回應時執行的步驟數 — 此範例使用 `100` 來保留主機記憶體)。\n",
        "\n",
        "**注意：** 如果你用完記憶體，請按一下 **Runtime** > **斷開連接並刪除執行時期** ，然後按一下 **Runtime** > **全部執行** 。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Gj9jRFI5Hrv2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompt:\n",
            "\n",
            "# What is the meaning of life?\n",
            "Output:\n",
            "\n",
            "\n",
            "The question of what the meaning of life is one that has occupied the minds of philosophers, theologians, and individuals for centuries. There is no single, universally accepted answer, but there are many different perspectives on this complex and multifaceted question.\n",
            "\n",
            "**Some common perspectives on the meaning of life include:**\n",
            "\n",
            "* **Biological perspective:** From a biological standpoint, the meaning of life is to survive and reproduce.\n",
            "* **Existential perspective:** Existentialists believe that life is not inherently meaningful and that\n"
          ]
        }
      ],
      "source": [
        "prompt = [\n",
        "    \"\\n# What is the meaning of life?\",\n",
        "]\n",
        "\n",
        "reply = sampler(input_strings=prompt,\n",
        "                total_generation_steps=100,\n",
        "                )\n",
        "\n",
        "for input_string, out_string in zip(prompt, reply.text):\n",
        "    print(f\"Prompt:\\n{input_string}\\nOutput:\\n{out_string}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njxRJy3qsBWw"
      },
      "source": [
        "5. (選填) 如果你已完成筆記本並想嘗試另一個提示，請執行此單元格來釋放記憶體。之後，你可以在步驟 3 中再次實例化「抽樣器」，並在步驟 4 中自訂並執行提示。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxX6qfFdNGHy"
      },
      "outputs": [],
      "source": [
        "del sampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzKsCGIN0yX5"
      },
      "source": [
        "## 瞭解更多\n",
        "\n",
        "- 你可以在 [GitHub 上的 Google DeepMind [`gemma` 函式庫](https://github.com/google-deepmind/gemma) 中進一步瞭解更多](https://github.com/google-deepmind/gemma/blob/main/gemma/params.py)，其中包含本教學課程中使用的模組文件字串，例如 [`gemma.params`](https://github.com/google-deepmind/gemma/blob/main/gemma/params.py)、\n",
        "[`gemma.transformer`](https://github.com/google-deepmind/gemma/blob/main/gemma/transformer.py) 和\n",
        "[`gemma.sampler`](https://github.com/google-deepmind/gemma/blob/main/gemma/sampler.py)。\n",
        "- 以下函式庫有其各自的說明文件網站： [核心 JAX](https://jax.readthedocs.io)、[Flax](https://flax.readthedocs.io) 和 [Orbax](https://orbax.readthedocs.io/)。\n",
        "- 對於 `sentencepiece` 分詞器/還原文件說明，請查看 [Google 的 `sentencepiece` GitHub 存放庫](https://github.com/google/sentencepiece)。\n",
        "- 對於 `kagglehub` 說明文件，請查看 [Kaggle 的 `kagglehub` GitHub 存放庫](https://github.com/Kaggle/kagglehub) 上的 `README.md`。\n",
        "- 瞭解如何 [將 Gemma 模型與 Google Cloud Vertex AI 整合使用](https://cloud.google.com/vertex-ai/docs/generative-ai/open-models/use-gemma)。\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "jax_inference.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}